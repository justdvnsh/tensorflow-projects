{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Divyansh\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we create a linear data of 500 data points b/w 1 and -1, and a target of 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_vals = tf.linspace(-1., 1., 500)\n",
    "target = tf.constant(0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.         -0.995992   -0.99198395 -0.98797596 -0.98396796 -0.9799599\n",
      " -0.9759519  -0.9719439  -0.96793586 -0.96392787]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(x_vals[:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we'll make teh L2 norm loss function, i.e. the Eucladian loss function , which is just the square of the difference of the data to target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eucladian Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_y_vals = tf.square(target - x_vals)\n",
    "l2_y_out = sess.run(l2_y_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         0.9920001  0.98403215 0.9760965  0.96819293 0.9603214\n",
      " 0.9524821  0.94467497 0.93689984 0.9291569 ]\n"
     ]
    }
   ],
   "source": [
    "print(l2_y_out[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Absolute Loss Function - L1 Norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         0.995992   0.99198395 0.98797596 0.98396796 0.9799599\n",
      " 0.9759519  0.9719439  0.96793586 0.96392787]\n"
     ]
    }
   ],
   "source": [
    "l1_y_vals = tf.abs(target - x_vals)\n",
    "l1_y_out = sess.run(l1_y_vals)\n",
    "print(l1_y_out[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The L2 norm is great for outliers becuase it is very curved near the target, so the algorithms can use this fact to converge to converge to the target more slowly, where as the L1 norm is not steep for larger values. The L1 norm is not smooth at target ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Huber Loss Function .\n",
    "This function takes the best of both worlds and thus is convex near the target and less steep for extreme values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.         -0.00049999 -0.00099799 -0.00149397 -0.00198794 -0.00247991\n",
      " -0.00296987 -0.00345781 -0.00394376 -0.00442769] \n",
      "\n",
      " [0.49509406 0.49117506 0.48726797 0.4833728  0.4794985  0.47563314\n",
      " 0.47178864 0.46795607 0.46414137 0.4603386 ]\n"
     ]
    }
   ],
   "source": [
    "delta1 = tf.constant(0.25)\n",
    "phuber1_y_vals = tf.multiply(tf.square(delta1), tf.square((target - x_vals)) - 1.)\n",
    "phuber1_y_out = sess.run(phuber1_y_vals)\n",
    "delta2 = tf.constant(5.)\n",
    "phuber2_y_vals = tf.multiply(tf.square(delta2), tf.sqrt(1. + tf.square((target - x_vals)/delta2)) - 1.)\n",
    "phuber2_y_out = sess.run(phuber2_y_vals)\n",
    "print(phuber1_y_out[:10],'\\n\\n', phuber2_y_out[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
